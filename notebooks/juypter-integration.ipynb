{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from ssc.hilda.perturbations import MissingValues\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class auto_validating:\n",
    "    def __init__(self, estimator, missing_values_in=[]):\n",
    "        self.estimator = estimator\n",
    "        self.missing_values_in = missing_values_in\n",
    "        \n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, type, value, traceback):\n",
    "        pass\n",
    "    \n",
    "    def __percentiles_of_probas(self, predictions):\n",
    "        probs_class_a = np.transpose(predictions)[0]\n",
    "        probs_class_b = np.transpose(predictions)[1]\n",
    "        features_a = np.percentile(probs_class_a, np.arange(0, 101, 5))\n",
    "        features_b = np.percentile(probs_class_b, np.arange(0, 101, 5))\n",
    "        return np.concatenate((features_a, features_b), axis=0)\n",
    "    \n",
    "    def __gen_perturbations(self, err_gen, columns, dataset_size=500):\n",
    "        # for fraction_of_values_to_delete in [0.01, 0.05, 0.25, 0.5, 0.75, 0.99]:\n",
    "        for _ in range(dataset_size):\n",
    "            yield err_gen(np.random.random(), columns, -1)\n",
    "    \n",
    "    def __train_meta_regressor(self, model, data, labels, perturbations):\n",
    "        X, y = [], []\n",
    "        for perturbation in perturbations:\n",
    "            corrupted_data = perturbation.transform(data)\n",
    "            \n",
    "            # predictions = model.predict_proba(corrupted_test_data)\n",
    "            # features = percentiles_of_probas(predictions)\n",
    "            X.append(self.__percentiles_of_probas(model.predict_proba(corrupted_data)))\n",
    "            \n",
    "            # score_on_corrupted_test_data = learner.score(y_test, model.predict(corrupted_test_data))\n",
    "            y.append(model.score(corrupted_data, labels))\n",
    "\n",
    "        param_grid = {\n",
    "            'learner__n_estimators': np.arange(5, 20, 5),\n",
    "            'learner__criterion': ['mae']\n",
    "        }\n",
    "\n",
    "        meta_regressor_pipeline = Pipeline([\n",
    "            ('scaling', StandardScaler()),\n",
    "            ('learner', RandomForestRegressor(criterion='mae'))\n",
    "        ])\n",
    "        \n",
    "        return (GridSearchCV(meta_regressor_pipeline, param_grid, scoring='neg_mean_absolute_error')\n",
    "                .fit(np.array(X), np.array(y)))\n",
    "    \n",
    "    def fit(self, data, labels):\n",
    "        print(\"intercepting training...\")\n",
    "        \n",
    "        model = self.estimator.fit(data, labels)\n",
    "        \n",
    "        # TODO We need to train a validation model for missing values here\n",
    "        \n",
    "        self.meta_regressor = self.__train_meta_regressor(model, data, labels,\n",
    "                                                          self.__gen_perturbations(MissingValues,\n",
    "                                                                                   self.missing_values_in,\n",
    "                                                                                   500))\n",
    "        \n",
    "        return PredictionInterceptor(model, self.meta_regressor)\n",
    "        \n",
    "    \n",
    "class PredictionInterceptor:\n",
    "    def __init__(self, transformer, meta_regressor):\n",
    "        self.transformer = transformer\n",
    "        self.meta_regressor = meta_regressor\n",
    "        \n",
    "    def __percentiles_of_probas(self, predictions):\n",
    "        probs_class_a = np.transpose(predictions)[0]\n",
    "        probs_class_b = np.transpose(predictions)[1]\n",
    "        features_a = np.percentile(probs_class_a, np.arange(0, 101, 5))\n",
    "        features_b = np.percentile(probs_class_b, np.arange(0, 101, 5))\n",
    "        return np.concatenate((features_a, features_b), axis=0)\n",
    "        \n",
    "    def score(self, data, labels):\n",
    "        print(\"Intercepting prediction...\")\n",
    "        \n",
    "        # TODO We need to apply the validation model here\n",
    "        \n",
    "        threshold = .01\n",
    "        features = self.__percentiles_of_probas(self.transformer.predict_proba(data))\n",
    "        predicted_score = self.meta_regressor.predict(features.reshape(1, -1))\n",
    "        real_score = self.transformer.score(data, labels)\n",
    "        diff = np.abs(real_score - predicted_score)\n",
    "        ratio = diff / real_score\n",
    "        print(diff, ratio)\n",
    "        if ratio > threshold:\n",
    "            print(\"WARNING! Performance drop: %.4f > %.2f, scores deviate by %.4f\" % (ratio, threshold, diff))\n",
    "        \n",
    "        return real_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercepting training...\n",
      "Intercepting prediction...\n",
      "[0.00118108] [0.00142215]\n",
      "Corrupting the test_data with 1% of missing values\n",
      "Intercepting prediction...\n",
      "[0.00121112] [0.00145854]\n",
      "0.8303648200466773\n",
      "\n",
      "Corrupting the test_data with 5% of missing values\n",
      "Intercepting prediction...\n",
      "[0.0014842] [0.00178873]\n",
      "0.8297506448839209\n",
      "\n",
      "Corrupting the test_data with 10% of missing values\n",
      "Intercepting prediction...\n",
      "[0.00144622] [0.00174709]\n",
      "0.8277852843631004\n",
      "\n",
      "Corrupting the test_data with 20% of missing values\n",
      "Intercepting prediction...\n",
      "[0.00374755] [0.00452451]\n",
      "0.8282766244933055\n",
      "\n",
      "Corrupting the test_data with 50% of missing values\n",
      "Intercepting prediction...\n",
      "[0.00423431] [0.00515346]\n",
      "0.8216435327355361\n",
      "\n",
      "Corrupting the test_data with 70% of missing values\n",
      "Intercepting prediction...\n",
      "[0.00390987] [0.00477932]\n",
      "0.8180813167915489\n",
      "\n",
      "Corrupting the test_data with 90% of missing values\n",
      "Intercepting prediction...\n",
      "[0.00338064] [0.0041486]\n",
      "0.8148876059452156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../resources/data/adult/adult.csv')\n",
    "\n",
    "train_data, test_data = train_test_split(data)\n",
    "y_train = np.array(train_data['class'] == '>50K')\n",
    "y_test = np.array(test_data['class'] == '>50K')\n",
    "\n",
    "    \n",
    "feature_transformation = ColumnTransformer(transformers=[\n",
    "    ('categorical', OneHotEncoder(handle_unknown='ignore'), ['workclass', 'occupation', 'marital_status', 'education']),\n",
    "    ('numeric', StandardScaler(), ['hours_per_week', 'age'])\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', feature_transformation),\n",
    "    ('learner', SGDClassifier(loss='log'))\n",
    "])\n",
    "\n",
    "with auto_validating(pipeline, missing_values_in=['education']) as validatable_pipeline:\n",
    "    model = validatable_pipeline.fit(train_data, y_train)\n",
    "\n",
    "model.score(test_data, y_test)\n",
    "\n",
    "for missing_value_ratio in [.01, .05, .1, .2, .5, .7, .9]:\n",
    "    print(\"Corrupting the test_data with %d%% of missing values\" % (int(round(100*missing_value_ratio)),))\n",
    "    corrupted_test_data = MissingValues(missing_value_ratio, ['education'], -1).transform(test_data)\n",
    "    print(model.score(corrupted_test_data, y_test))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another version of the API, same-same but different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Validatable:\n",
    "    def __init__(self, estimator):\n",
    "        self.estimator = estimator\n",
    "        \n",
    "    def check_on(self, data, labels):\n",
    "        self.test_data = data\n",
    "        self.test_labels = labels\n",
    "        return self\n",
    "        \n",
    "    def check_for(self, missing_values_in=[]):\n",
    "        self.missing_values_in = missing_values_in\n",
    "        return self\n",
    "        \n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, type, value, traceback):\n",
    "        pass\n",
    "    \n",
    "    def __percentiles_of_probas(self, predictions):\n",
    "        probs_class_a = np.transpose(predictions)[0]\n",
    "        probs_class_b = np.transpose(predictions)[1]\n",
    "        features_a = np.percentile(probs_class_a, np.arange(0, 101, 5))\n",
    "        features_b = np.percentile(probs_class_b, np.arange(0, 101, 5))\n",
    "        return np.concatenate((features_a, features_b), axis=0)\n",
    "    \n",
    "    def __gen_perturbations(self, err_gen, columns, dataset_size=500):\n",
    "        # for fraction_of_values_to_delete in [0.01, 0.05, 0.25, 0.5, 0.75, 0.99]:\n",
    "        for _ in range(dataset_size):\n",
    "            yield err_gen(np.random.random(), columns, -1)\n",
    "            \n",
    "    def __train_meta_regressor(self, model, data, labels, perturbations):\n",
    "        print(\"Generating corrupted data\")\n",
    "        X, y = [], []\n",
    "        for perturbation in perturbations:\n",
    "            corrupted_data = perturbation.transform(data)\n",
    "            \n",
    "            # predictions = model.predict_proba(corrupted_test_data)\n",
    "            # features = percentiles_of_probas(predictions)\n",
    "            X.append(self.__percentiles_of_probas(model.predict_proba(corrupted_data)))\n",
    "            \n",
    "            # score_on_corrupted_test_data = learner.score(y_test, model.predict(corrupted_test_data))\n",
    "            y.append(model.score(corrupted_data, labels))\n",
    "\n",
    "        param_grid = {\n",
    "            'learner__n_estimators': np.arange(5, 20, 5),\n",
    "            'learner__criterion': ['mae']\n",
    "        }\n",
    "\n",
    "        meta_regressor_pipeline = Pipeline([\n",
    "            ('scaling', StandardScaler()),\n",
    "            ('learner', RandomForestRegressor(criterion='mae'))\n",
    "        ])\n",
    "        \n",
    "        print(\"Training the meta_regressor\")\n",
    "        return (GridSearchCV(meta_regressor_pipeline, param_grid, scoring='neg_mean_absolute_error')\n",
    "                .fit(np.array(X), np.array(y)))\n",
    "    \n",
    "    def fit(self, data, labels):\n",
    "        print(\"Training the model\")\n",
    "        # NB: encapsulate 'model' inside the class or not? \n",
    "        model = self.estimator.fit(data, labels)\n",
    "        \n",
    "        # TODO We need to train a validation model for missing values here\n",
    "        self.meta_regressor = self.__train_meta_regressor(model, data, labels,\n",
    "                                                          self.__gen_perturbations(MissingValues,\n",
    "                                                                                   self.missing_values_in,\n",
    "                                                                                   500))\n",
    "        self.score(self.test_data, self.test_labels)\n",
    "        \n",
    "        # Returns a trained model, as a regular .fit method\n",
    "        return model\n",
    "    \n",
    "    def score(self, data, labels):\n",
    "        print(\"Validating the model\")\n",
    "        threshold = .01\n",
    "        features = self.__percentiles_of_probas(model.predict_proba(data))\n",
    "        predicted_score = self.meta_regressor.predict(features.reshape(1, -1))\n",
    "        real_score = model.score(data, labels)\n",
    "        diff = np.abs(real_score - predicted_score)\n",
    "        ratio = diff / real_score\n",
    "        print(diff, ratio)\n",
    "        if ratio > threshold:\n",
    "            print(\"WARNING! Performance drop: %.4f > %.2f, scores deviate by %.4f\" % (ratio, threshold, diff))\n",
    "        return real_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model\n",
      "Generating corrupted data\n",
      "Training the meta_regressor\n",
      "Validating the model\n",
      "[0.01071138] [0.01288055]\n",
      "WARNING! Performance drop: 0.0129 > 0.01, scores deviate by 0.0107\n",
      "Corrupting the test_data with 1% of missing values\n",
      "Validating the model\n",
      "[0.01077417] [0.01295606]\n",
      "WARNING! Performance drop: 0.0130 > 0.01, scores deviate by 0.0108\n",
      "0.8315931703721902\n",
      "\n",
      "Corrupting the test_data with 5% of missing values\n",
      "Validating the model\n",
      "[0.0109899] [0.01322329]\n",
      "WARNING! Performance drop: 0.0132 > 0.01, scores deviate by 0.0110\n",
      "0.831101830241985\n",
      "\n",
      "Corrupting the test_data with 10% of missing values\n",
      "Validating the model\n",
      "[0.00846226] [0.01021671]\n",
      "WARNING! Performance drop: 0.0102 > 0.01, scores deviate by 0.0085\n",
      "0.8282766244933055\n",
      "\n",
      "Corrupting the test_data with 20% of missing values\n",
      "Validating the model\n",
      "[0.00896757] [0.01085415]\n",
      "WARNING! Performance drop: 0.0109 > 0.01, scores deviate by 0.0090\n",
      "0.8261884289399337\n",
      "\n",
      "Corrupting the test_data with 50% of missing values\n",
      "Validating the model\n",
      "[0.00856444] [0.01045951]\n",
      "WARNING! Performance drop: 0.0105 > 0.01, scores deviate by 0.0086\n",
      "0.8188183269868566\n",
      "\n",
      "Corrupting the test_data with 70% of missing values\n",
      "Validating the model\n",
      "[0.00382621] [0.00472243]\n",
      "0.8102198747082668\n",
      "\n",
      "Corrupting the test_data with 90% of missing values\n",
      "Validating the model\n",
      "[0.00100675] [0.00125053]\n",
      "0.8050608033411129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with Validatable(pipeline) as validatable_pipeline:\n",
    "    validatable_pipeline.check_on(test_data, y_test)\n",
    "    validatable_pipeline.check_for(missing_values_in=['education', 'workclass'])\n",
    "    \n",
    "    model = validatable_pipeline.fit(train_data, y_train)\n",
    "    \n",
    "model.score(test_data, y_test)\n",
    "\n",
    "for missing_value_ratio in [.01, .05, .1, .2, .5, .7, .9]:\n",
    "    print(\"Corrupting the test_data with %d%% of missing values\" % (int(round(100*missing_value_ratio)),))\n",
    "    corrupted_test_data = MissingValues(missing_value_ratio, ['education', 'workclass'], -1).transform(test_data)\n",
    "    print(validatable_pipeline.score(corrupted_test_data, y_test))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
