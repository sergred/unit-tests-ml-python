{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class auto_validating:\n",
    "    def __init__(self, estimator, missing_values_in=[]):\n",
    "        self.estimator = estimator\n",
    "        self.missing_values_in = missing_values_in\n",
    "        \n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, type, value, traceback):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, data, labels):\n",
    "        print(\"intercepting training...\")\n",
    "        \n",
    "        # TODO We need to train a validation model for missing values here\n",
    "        \n",
    "        model = self.estimator.fit(data, labels)    \n",
    "        return PredictionInterceptor(model)\n",
    "        \n",
    "    \n",
    "class PredictionInterceptor:\n",
    "    def __init__(self, transformer):\n",
    "        self.transformer = transformer\n",
    "        \n",
    "    def score(self, data, labels):\n",
    "        print(\"Intercepting prediction...\")\n",
    "        \n",
    "        # TODO We need to apply the validation model here\n",
    "        \n",
    "        return self.transformer.score(data, labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercepting training...\n",
      "Intercepting prediction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:465: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py:605: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8295049748188184"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../resources/data/adult/adult.csv')\n",
    "\n",
    "train_data, test_data = train_test_split(data)\n",
    "y_train = np.array(train_data['class'] == '>50K')\n",
    "y_test = np.array(test_data['class'] == '>50K')\n",
    "\n",
    "    \n",
    "feature_transformation = ColumnTransformer(transformers=[\n",
    "    ('categorical', OneHotEncoder(handle_unknown='ignore'), ['workclass', 'occupation', 'marital_status', 'education']),\n",
    "    ('numeric', StandardScaler(), ['hours_per_week', 'age'])\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', feature_transformation),\n",
    "    ('learner', SGDClassifier(loss='log'))\n",
    "])\n",
    "\n",
    "with auto_validating(pipeline, missing_values_in=['education']) as validatable_pipeline:\n",
    "    model = validatable_pipeline.fit(train_data, y_train)\n",
    "\n",
    "model.score(test_data, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
