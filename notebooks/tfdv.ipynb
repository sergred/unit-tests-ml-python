{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_data_validation as tfdv\n",
    "from google.protobuf import text_format\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from analyzers import DataType \n",
    "\n",
    "np.random.seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model on perturbed data.\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   54.0s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy', 'on train data: ', 0.8038262255878836)\n",
      "('accuracy', 'on test data: ', 0.7895408163265306)\n",
      "('accuracy', 'on target data: ', 0.8068833652007649)\n",
      "\n",
      "Training meta regressor on perturbed test data.\n",
      "\n",
      "Evaluating meta regressor on perturbed target data.\n",
      "MSE 0.00034, MAE 0.0173\n",
      "Writing plot to /home/reds/myrepo/unit-tests-ml-python/ssc/hilda/../figures/adult_income_balanced__missing_values_at_random__logistic_regression__accuracy.pdf\n",
      "/home/reds/myrepo/unit-tests-ml-python/ssc/hilda/../results/adult_income_balanced__missing_values_at_random__logistic_regression__accuracy.tsv\n",
      "reapply_perturbations\tadult_income_balanced\t0.8038262255878836\t0.7895408163265306\t0.8068833652007649\tlogistic_regression\taccuracy\tmissing_values_at_random\t0.00033986933018817896\t0.01733073822761259\t/home/reds/myrepo/unit-tests-ml-python/ssc/hilda/../figures/adult_income_balanced__missing_values_at_random__logistic_regression__accuracy.pdf\n"
     ]
    }
   ],
   "source": [
    "from ssc.hilda.datasets import *\n",
    "from ssc.hilda.perturbations import *\n",
    "from ssc.hilda.learners import *\n",
    "from ssc.hilda.experiments import *\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Pick a dataset\n",
    "# dataset = CardioDataset()\n",
    "dataset = BalancedAdultDataset()\n",
    "# dataset = AdultDataset()\n",
    "\n",
    "def gen_perturbations():\n",
    "    for num_columns_affected in range(1, 5):\n",
    "        for fraction_of_values_to_delete in [0.0, 0.05, 0.25, 0.5, 0.75, 0.99]:\n",
    "            for _ in range(100):\n",
    "                columns_affected = np.random.choice(dataset.categorical_columns, num_columns_affected)\n",
    "                yield MissingValues(fraction_of_values_to_delete, columns_affected, -1)\n",
    "\n",
    "# generate a bunch of perturbations for training\n",
    "perturbations_for_training = list(gen_perturbations())\n",
    "\n",
    "# generate a bunch of perturbations for evaluation\n",
    "perturbations_for_evaluation = list(gen_perturbations())\n",
    "\n",
    "# name the perturbations\n",
    "perturbations_name = \"missing_values_at_random\"\n",
    "\n",
    "# define the learner\n",
    "# learner = DNN('accuracy')\n",
    "# learner = LogisticRegression('roc_auc')\n",
    "learner = LogisticRegression('accuracy')\n",
    "\n",
    "# run an experiment\n",
    "log_line, model, mse, mae = reapply_perturbations(dataset, learner, perturbations_for_training,\n",
    "                                                  perturbations_for_evaluation, perturbations_name)\n",
    "\n",
    "# print(\"----------------------------------------------------------------------------------------------\")\n",
    "# print(log_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anomaly short description</th>\n",
       "      <th>Anomaly long description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'education'</th>\n",
       "      <td>Unexpected string values</td>\n",
       "      <td>Examples contain values missing from the schema: -1 (~39%).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'marital_status'</th>\n",
       "      <td>Unexpected string values</td>\n",
       "      <td>Examples contain values missing from the schema: -1 (~39%).</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Anomaly short description  \\\n",
       "Feature name                                 \n",
       "'education'       Unexpected string values   \n",
       "'marital_status'  Unexpected string values   \n",
       "\n",
       "                                                      Anomaly long description  \n",
       "Feature name                                                                    \n",
       "'education'       Examples contain values missing from the schema: -1 (~39%).   \n",
       "'marital_status'  Examples contain values missing from the schema: -1 (~39%).   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# def train_test_split_csv(data_path, file_name, test_ratio=.2):\n",
    "#     data = pd.read_csv(os.path.join(data_path, file_name))\n",
    "#     train, test = train_test_split(data, test_size=test_ratio, random_state=1)\n",
    "#     if not os.path.exists(os.path.join(data_path, 'tmp')):\n",
    "#         os.makedirs(os.path.join(data_path, 'tmp'))\n",
    "#     train.to_csv(os.path.join(data_path, 'tmp/train.csv'))\n",
    "#     test.to_csv(os.path.join(data_path, 'tmp/test.csv'))\n",
    "\n",
    "data_path, file_name = \"/\".join(dataset.path.split('/')[:-1]), dataset.path.split('/')[-1]\n",
    "# train_test_split_csv(data_path, file_name, test_ratio=.2)\n",
    "\n",
    "X_train, X_test, X_target = learner.split(dataset.df)\n",
    "\n",
    "columns_affected = np.random.choice(dataset.categorical_columns, 3)\n",
    "corrupted_X_test = MissingValues(.4, columns_affected, -1).transform(X_test)\n",
    "corrupted_X_test.to_csv(os.path.join(data_path, 'tmp/corrupted_test.csv'))\n",
    "\n",
    "X_train.to_csv(os.path.join(data_path, 'tmp/X_train.csv'))\n",
    "X_test.to_csv(os.path.join(data_path, 'tmp/X_test.csv'))\n",
    "\n",
    "train_stats = tfdv.generate_statistics_from_csv(os.path.join(data_path, 'tmp/X_train.csv'), delimiter=',')\n",
    "test_stats = tfdv.generate_statistics_from_csv(os.path.join(data_path, 'tmp/X_test.csv'), delimiter=',')\n",
    "\n",
    "corrupted_test_stats = tfdv.generate_statistics_from_csv(os.path.join(data_path, 'tmp/corrupted_test.csv'), delimiter=',')\n",
    "\n",
    "schema = tfdv.infer_schema(train_stats)\n",
    "# print(schema)\n",
    "# tfdv.display_schema(schema)\n",
    "anomalies = tfdv.validate_statistics(statistics=corrupted_test_stats, schema=schema)\n",
    "# print(anomalies)\n",
    "tfdv.display_anomalies(anomalies)\n",
    "# print(text_format.MessageToString(anomalies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFRecordHelper:\n",
    "    class __TFRecordHelper:\n",
    "        def __init__(self):\n",
    "            self.foo = dict({\n",
    "                DataType.STRING: lambda x, y: x.bytes_list.value.extend([y]),\n",
    "                DataType.INTEGER: lambda x, y: x.int64_list.value.extend([y]),\n",
    "                DataType.FLOAT: lambda x, y: x.float_list.value.extend([y]),\n",
    "                DataType.OBJECT: lambda x, y: x.bytes_list.value.extend([y])\n",
    "            })\n",
    "            self.data_type = dict({\n",
    "                'int': DataType.INTEGER,\n",
    "                'int32': DataType.INTEGER,\n",
    "                'int64': DataType.INTEGER,\n",
    "                'float': DataType.FLOAT,\n",
    "                'float32': DataType.FLOAT,\n",
    "                'float64': DataType.FLOAT,\n",
    "                'byte': DataType.OBJECT,\n",
    "                # 'string': DataType.STRING,\n",
    "                'object': DataType.OBJECT\n",
    "            })\n",
    "\n",
    "        def run(self, example, feature_name, dtype, val):\n",
    "            if not isinstance(dtype, DataType):\n",
    "                dtype = self.data_type[str(dtype)]\n",
    "            return self.foo[dtype](example.features.feature[feature_name], val)\n",
    "\n",
    "    instance = None\n",
    "\n",
    "    def __init__(self):\n",
    "        if not TFRecordHelper.instance:\n",
    "            TFRecordHelper.instance = TFRecordHelper.__TFRecordHelper()\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self.instance, name)\n",
    "\n",
    "\n",
    "def convert_csv_to_tfrecord(data_path, file_name, dtypes=None):\n",
    "    filename = os.path.join(data_path, file_name.split('.')[0] + '.tfrecords')\n",
    "    data = pd.read_csv(os.path.join(data_path, file_name))\n",
    "    helper = TFRecordHelper()\n",
    "    columns = data.columns\n",
    "    if dtypes is None:\n",
    "        dtypes = data.dtypes\n",
    "    with tf.python_io.TFRecordWriter(filename) as writer:\n",
    "        for i in range(data.shape[0]):\n",
    "            example = tf.train.Example()\n",
    "            for j in range(data.shape[1]):\n",
    "                helper.run(example, columns[j], dtypes[j], data.iloc[i, j])\n",
    "            writer.write(example.SerializeToString())\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfrecord_filename = convert_csv_to_tfrecord(data_path, 'tmp/X_train.csv')\n",
    "test_tfrecord_filename = convert_csv_to_tfrecord(data_path, 'tmp/X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python = [\"/home/reds/install/miniconda3/envs/python2/bin/python\"]\n",
    "\n",
    "dir_path = os.path.join(globals()['_dh'][0], '../third_party/data-linter')\n",
    "\n",
    "!{python[0]} {dir_path}/demo/summarize_data.py --dataset_path {train_tfrecord_filename} \\\n",
    "  --stats_path /tmp/adult_summary.bin \\\n",
    "  --dataset_name adult\n",
    "\n",
    "!{python[0]} {dir_path}/data_linter_main.py --dataset_path {test_tfrecord_filename} \\\n",
    "  --stats_path /tmp/adult_summary.bin \\\n",
    "  --results_path /tmp/datalinter/results/lint_results.bin\n",
    "\n",
    "!{python[0]} {dir_path}/lint_explorer_main.py --results_path /tmp/datalinter/results/lint_results.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_on(X_test, X_target, evaluation=True):\n",
    "    def percentiles_of_probas(predictions):\n",
    "        probs_class_a = np.transpose(predictions)[0]\n",
    "        probs_class_b = np.transpose(predictions)[1]\n",
    "        features_a = np.percentile(probs_class_a, np.arange(0, 101, 5))\n",
    "        features_b = np.percentile(probs_class_b, np.arange(0, 101, 5))\n",
    "        return np.concatenate((features_a, features_b), axis=0)\n",
    "    \n",
    "    def validate(f):\n",
    "        def wrapper(*args):\n",
    "            y_test = dataset.labels_from(X_test)\n",
    "            y_target = dataset.labels_from(X_target)\n",
    "\n",
    "            learner = f(*args)\n",
    "            model = learner.model\n",
    "\n",
    "            # Training\n",
    "            print(\"\\nTraining meta regressor on perturbed test data.\")\n",
    "            perturbations_for_training = gen_perturbations()\n",
    "            meta_regressor = train_random_forest_regressor(X_test, y_test,\n",
    "                                                           perturbations_for_training,\n",
    "                                                           model, learner)\n",
    "\n",
    "            # Evaluation\n",
    "            print(\"\\nEvaluating meta regressor on perturbed target data.\")\n",
    "            predicted_scores, true_scores = [], []\n",
    "\n",
    "            for perturbation in learner.perturbations:\n",
    "                corrupted_target_data = perturbation.transform(X_target)\n",
    "\n",
    "                predictions = model.predict_proba(corrupted_target_data)\n",
    "                features = percentiles_of_probas(predictions)\n",
    "\n",
    "                score_on_corrupted_target_data = learner.score(y_target, model.predict(corrupted_target_data))\n",
    "                predicted_score_on_corrupted_target_data = meta_regressor.predict([features])\n",
    "\n",
    "                predicted_scores.append(predicted_score_on_corrupted_target_data)\n",
    "                true_scores.append(score_on_corrupted_target_data)\n",
    "\n",
    "            from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "            mse = mean_squared_error(true_scores, predicted_scores)\n",
    "            mae = mean_absolute_error(true_scores, predicted_scores)\n",
    "\n",
    "            print(\"MSE %.5f, MAE %.5f\" % (mse, mae))\n",
    "            \n",
    "            learner.meta_regressor = meta_regressor\n",
    "            \n",
    "            threshold = .01 # 1%\n",
    "                        \n",
    "            # Check whether mean of true_scores makes sense\n",
    "            print(np.mean(true_scores), mae / np.mean(true_scores))\n",
    "            if mae / np.mean(true_scores) > threshold:\n",
    "                print(\"WARNING! Performance drop\")\n",
    "            else:\n",
    "                print(\"Everything is fine\")\n",
    "            \n",
    "            return learner\n",
    "        return wrapper\n",
    "    return validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training meta regressor on perturbed test data.\n",
      "\n",
      "Evaluating meta regressor on perturbed target data.\n",
      "MSE 0.00007, MAE 0.00572\n"
     ]
    }
   ],
   "source": [
    "@validate_on(X_test, X_target, evaluation=False)\n",
    "def learner_foo():\n",
    "    dataset = BalancedAdultDataset()\n",
    "    learner = LogisticRegression('accuracy')\n",
    "    # X_train = pd.read_csv(os.path.join(data_path, 'tmp/X_train.csv'))\n",
    "    model = learner.fit(dataset, X_train)\n",
    "    learner.model = model\n",
    "    learner.perturbations = gen_perturbations()\n",
    "    return learner\n",
    "\n",
    "\n",
    "learner = learner_foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anomaly short description</th>\n",
       "      <th>Anomaly long description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'marital_status'</th>\n",
       "      <td>Unexpected string values</td>\n",
       "      <td>Examples contain values missing from the schema: -1 (&lt;1%).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'workclass'</th>\n",
       "      <td>Unexpected string values</td>\n",
       "      <td>Examples contain values missing from the schema: -1 (&lt;1%).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'occupation'</th>\n",
       "      <td>Unexpected string values</td>\n",
       "      <td>Examples contain values missing from the schema: -1 (&lt;1%).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'education'</th>\n",
       "      <td>Unexpected string values</td>\n",
       "      <td>Examples contain values missing from the schema: -1 (&lt;1%).</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Anomaly short description  \\\n",
       "Feature name                                 \n",
       "'marital_status'  Unexpected string values   \n",
       "'workclass'       Unexpected string values   \n",
       "'occupation'      Unexpected string values   \n",
       "'education'       Unexpected string values   \n",
       "\n",
       "                                                     Anomaly long description  \n",
       "Feature name                                                                   \n",
       "'marital_status'  Examples contain values missing from the schema: -1 (<1%).   \n",
       "'workclass'       Examples contain values missing from the schema: -1 (<1%).   \n",
       "'occupation'      Examples contain values missing from the schema: -1 (<1%).   \n",
       "'education'       Examples contain values missing from the schema: -1 (<1%).   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns_affected = dataset.categorical_columns\n",
    "new_corrupted_X_test = MissingValues(.004, columns_affected, -1).transform(X_test)\n",
    "new_corrupted_X_test.to_csv(os.path.join(data_path, 'tmp/new_corrupted_test.csv'))\n",
    "\n",
    "train_stats = tfdv.generate_statistics_from_csv(os.path.join(data_path, 'tmp/X_train.csv'), delimiter=',')\n",
    "test_stats = tfdv.generate_statistics_from_csv(os.path.join(data_path, 'tmp/X_test.csv'), delimiter=',')\n",
    "\n",
    "corrupted_test_stats = tfdv.generate_statistics_from_csv(os.path.join(data_path, 'tmp/new_corrupted_test.csv'), delimiter=',')\n",
    "\n",
    "schema = tfdv.infer_schema(train_stats)\n",
    "# print(schema)\n",
    "# tfdv.display_schema(schema)\n",
    "anomalies = tfdv.validate_statistics(statistics=corrupted_test_stats, schema=schema)\n",
    "# print(anomalies)\n",
    "tfdv.display_anomalies(anomalies)\n",
    "# print(text_format.MessageToString(anomalies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training meta regressor on perturbed test data.\n"
     ]
    }
   ],
   "source": [
    "def gen_perturbations():\n",
    "    for num_columns_affected in range(1, 5):\n",
    "        for fraction_of_values_to_delete in [0.7, 0.8, 0.9]:\n",
    "            for _ in range(100):\n",
    "                columns_affected = dataset.categorical_columns\n",
    "                yield MissingValues(fraction_of_values_to_delete, columns_affected, -1)\n",
    "\n",
    "@validate_on(X_test, X_target, evaluation=False)\n",
    "def learner_foo():\n",
    "    dataset = BalancedAdultDataset()\n",
    "    learner = LogisticRegression('accuracy')\n",
    "    # X_train = pd.read_csv(os.path.join(data_path, 'tmp/X_train.csv'))\n",
    "    model = learner.fit(dataset, X_train)\n",
    "    learner.model = model\n",
    "    learner.perturbations = gen_perturbations()\n",
    "    return learner\n",
    "\n",
    "\n",
    "learner = learner_foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
